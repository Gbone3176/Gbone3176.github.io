---
title: "VAP-Diffusion: Enriching Descriptions with MLLMs for Enhanced Medical Image Generation"
collection: publications
category: manuscripts
permalink: /publication/2025-09-03-paper-MICCAI2025
excerpt: '提出基础视觉提示策略，基于CoT方法逐步提示MLLM准确描述医学图像，挖掘医学图像复杂视觉属性信息。同时提出针对扩散模型的跨模态原型注入机制，通过构造基于类别的多模态原型库，辅助扩散模型利用视觉属性提示重建图像数据分布'
date: 2025-09-03
venue: 'MICCAI'
# slidesurl: 'http://academicpages.github.io/files/slides2.pdf'
paperurl: 'http://academicpages.github.io/files\MICCAI-VAP-Diffusion.pdf'
citation: 'updating...'
---

As the appearance of medical images is influenced by multiple underlying factors, generative models require rich attribute informationbeyond labels to produce realistic and diverse images. For instance,generating an image of skin lesion with specific patterns demands descriptionsthat go beyond diagnosis, such as shape, size, texture, and color.However, such detailed descriptions are not always accessible. To addressthis, we explore a framework, termed Visual Attribute Prompts (VAP)-Diffusion, to leverage external knowledge from pre-trained Multi-modalLarge Language Models (MLLMs) to improve the quality and diversity of medical image generation. First, to derive descriptions from MLLMs without hallucination, we design a series of prompts following Chainof-Thoughts for common medical imaging tasks, including dermatologic, colorectal, and chest X-ray images. Generated descriptions are utilized during training and stored across different categories. During testing, descriptions are randomly retrieved from the corresponding category for inference. Moreover, to make the generator robust to unseen combination of descriptions at the test time, we propose a Prototype Condition Mechanism that restricts test embeddings to be similar to those from training. Experiments on three common types of medical imaging across four datasets verify the effectiveness of VAP-Diffusion.